{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited by **Tian Heng** [tianheng@pku.edu.cn], 2020.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python学习要诀：\n",
    "\n",
    "- <font color=red size=4>目标明确，带着任务学习</font>\n",
    "\n",
    "\n",
    "- <font color=red size=4>善用百度，同时结合实际</font>\n",
    "\n",
    "\n",
    "- <font color=red size=4>勇于尝试，快速试错</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐阅读： [Python3官方中文文档](https://docs.python.org/zh-cn/3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文档推荐使用 [jupyter notebook](https://jupyter.org/index.html) 阅读。[Python](https://www.python.org/) 开发环境推荐使用 [Anaconda](https://www.anaconda.com/) ，2020.11版本下载地址 [百度网盘](https://pan.baidu.com/s/1FFsgOVwiUpldOkenNkAwWQ) 验证码：uz9w。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 启动与停止Jupyter Notebook服务\n",
    "- 从开始菜单找到Anaconda Navigator，并运行\n",
    "![0-5](img/0-5.png)\n",
    "\n",
    "\n",
    "- 如果需要停止Jupyter Notebook Server，<font color=red>仅关闭浏览器是没用的</font>，需要点击如下按钮\n",
    "![0-4](img/0-4.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 插件与库的安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文档带有目录，需要安装jupyter_contrib_nbextensions插件才能正常显示，安装步骤如下：\n",
    "\n",
    "- 打开 Anaconda Navigator，点击 Environments -> base (root) -> Open Terminal：\n",
    "![0-1](img/0-1.png)\n",
    "\n",
    "\n",
    "- 依次输入以下命令，每次输入一行，并等待安装完成：\n",
    "\n",
    "<code>pip install jupyter_contrib_nbextensions -i https://pypi.tuna.tsinghua.edu.cn/simple/</code>\n",
    "\n",
    "<code>jupyter contrib nbextension install --user</code>\n",
    "\n",
    "<code>pip install jupyter_nbextensions_configurator -i https://pypi.tuna.tsinghua.edu.cn/simple/</code>\n",
    "\n",
    "<code>jupyter nbextensions_configurator enable --user</code>\n",
    "\n",
    "\n",
    "- 全部命令执行完后，重启 Jupyter Notebook，在根目录页的标签栏里多了一个 Nbextensions 标签：\n",
    "![0-2](img/0-2.png)\n",
    "\n",
    "\n",
    "- 勾选需要的插件，我们这里勾选目录（Table of Contents）、代码提示（Hinterland）（如无法勾选，先去掉 **disable ...** 之前的√，勾选完成后再补上）：\n",
    "![0-3](img/0-3.png)\n",
    "\n",
    "\n",
    "- 一些包的安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "jupyter notebook内的 ! 可用于执行外部命令\n",
    "用 -i 指定安装源，这里我们使用清华tuna源\n",
    "'''\n",
    "!pip install mlxtend -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install fuzzywuzzy -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有可能你会遇到……\n",
    "- 如果关闭了浏览器页面，但notebook服务没有停止，重新打开notebook页面，只需要在浏览器输入 **localhost:8888/tree** 即可。\n",
    "\n",
    "\n",
    "- 但可能会要求你输入密码，如下图所示。\n",
    "![setpw1](img/jupyter_setpw.PNG)\n",
    "\n",
    "\n",
    "- 按页面提示，通过 **token** 重置密码：\n",
    "  - 按 **0.1** 节的方法打开 **终端（terminal）**\n",
    "  - 输入命令 `jupyter notebook list` 查看token，如下图\n",
    "  ![setpw2](img/jupyter_setpw2.PNG)\n",
    "  - 在重设密码的界面填入token和新密码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python入门\n",
    "- 推荐 **菜鸟教程** 的 [Python教程](https://www.runoob.com/python3/python3-tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python语言是一种解释型、面向对象、动态数据类型的高级程序设计语言\n",
    "![1-1](img/1-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python语言的优点：\n",
    "\n",
    "1.优雅、简单、明确。让数据分析师们摆脱了程序本身语法规则的泥潭，更快的进行数据分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| C语言 | Python |\n",
    "| -- | -- |\n",
    "| ![1-2](img/1-2.jpg) | ![1-3](img/1-3.jpg) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2.标准库丰富。完善的基础代码库，覆盖了网络通信、文件处理、数据库接口、图形系统、XML处理等大量内容。\n",
    "  \n",
    "**Python之禅 by Tim Peters**\n",
    "- 优美胜于丑陋（Python 以编写优美的代码为目标）\n",
    "- 明了胜于晦涩（优美的代码应当是明了的，命名规范，风格相似）\n",
    "- 简洁胜于复杂（优美的代码应当是简洁的，不要有复杂的内部实现）\n",
    "- 复杂胜于凌乱（如果复杂不可避免，那代码间也不能有难懂的关系，要保持接口简洁）\n",
    "- 扁平胜于嵌套（优美的代码应当是扁平的，不能有太多的嵌套）\n",
    "- 间隔胜于紧凑（优美的代码有适当的间隔，不要奢望一行代码解决问题）\n",
    "- 可读性很重要（优美的代码是可读的）\n",
    "- 即便假借特例的实用性之名，也不可违背这些规则（这些规则至高无上）\n",
    "- 不要包容所有错误，除非你确定需要这样做（精准地捕获异常，不写 except:pass 风格的代码）\n",
    "- 当存在多种可能，不要尝试去猜测\n",
    "- 而是尽量找一种，最好是唯一一种明显的解决方案（如果不确定，就用穷举法）\n",
    "- 虽然这并不容易，因为你不是 Python 之父（这里的 Dutch 是指 Guido ）\n",
    "- 做也许好过不做，但不假思索就动手还不如不做（动手之前要细思量）\n",
    "- 如果你无法向人描述你的方案，那肯定不是一个好方案；反之亦然（方案测评标准）\n",
    "- 命名空间是一种绝妙的理念，我们应当多加利用（倡导与号召）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this\n",
    "# 仅第一次import时有效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.良好的可扩展性。大量的第三方模块，覆盖了科学计算、Web开发、数据接口、图形系统等众多领域，开发的代码通过很好的封装，也可以作为第三方模块给别人使用。如Pandas、Numpy、Seaborn、Scikit-learn等等。\n",
    "\n",
    "4.免费、开源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python语言的缺点：\n",
    "  - 运行速度慢（与C/C++等编译型语言相比）\n",
    "  - 代码加密难\n",
    "  - “烦人”的缩进规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "print(\"It's True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    print(\"It's True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开发环境（以Jupyter Notebook为例）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节课外阅读： [Jupyter Notebook介绍、安装及使用教程](https://www.jianshu.com/p/91365f343585)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。简而言之，Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 支持Markdown和LaTeX语法（例如本文档）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 此外还有\n",
    "  - 交互式计算和开发环境：IPython\n",
    "  - 集成开发环境（IDE）：[PyCharm](https://www.jetbrains.com/pycharm/)(目前最热门的Python IDE，[社区版](https://www.jetbrains.com/pycharm/)免费，buu.edu.cn结尾的邮箱可以申请[student license](https://www.jetbrains.com/community/education/#students)，免费使用专业版1年，可续期)，Spyder（Anaconda内置）\n",
    "  - 数据科学计算平台：[Anaconda](https://www.anaconda.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本语法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量与常量\n",
    "- 用来存储一些之后可能会变化的值。通过赋值运算符 **=** 把变量名和想要赋予变量的值连接起来，变量的赋值操作就完成了声明和定义的的过程，在其他语言中则需要制定类型。同一变量可以反复赋值，而且可以是不同类型的变量，这也是Python语言称之为\n",
    "<font color=red>动态语言</font>\n",
    "的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一条注释，单行注释以#开头\n",
    "'''\n",
    "这也是一条注释\n",
    "多行注释用3层单引号/双引号包裹\n",
    "'''\n",
    "\"\"\"\n",
    "例如这样\n",
    "以及前一条注释\n",
    "\"\"\"\n",
    "id = 12345\n",
    "print(id, type(id))\n",
    "id = '12345'\n",
    "print(id, type(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 变量名必须是大小写英文字母、数字或下划线 _ 的组合，不能用数字开头，并且\n",
    "<font color=red>对大小写敏感</font>\n",
    "- Python中定义了一些关键字，不能用于变量命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "print(keyword.kwlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本数据类型\n",
    "- 包括整型（int）、浮点型（float）、字符串（str）、布尔型（bool）、空值（NoneType）。使用\n",
    "<font color=green>type()</font>\n",
    "函数查看变量的数据类型。也可以使用\n",
    "<font color=green>isinstance(变量, 类型)</font>\n",
    "判断变量是否是某类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(2))\n",
    "print(type(3.14159265))\n",
    "print(type('Beijing Union University'))\n",
    "print(type(True))\n",
    "print(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance('Beijing Union University', int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 变量类型转换：使用\n",
    "<font color=green>int()</font>,\n",
    "<font color=green>float()</font>,\n",
    "<font color=green>str()</font>\n",
    "和\n",
    "<font color=green>bool()</font>\n",
    "函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "print(id, type(id))\n",
    "print(float(id), type(float(id)))\n",
    "print(str(id), type(str(id)))\n",
    "print(bool(id), type(bool(id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 算术运算符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 运算 | 说明 |\n",
    "| -- | -- |\n",
    "| a + b | a加b |\n",
    "| a - b | a减b |\n",
    "| a * b | a乘以b |\n",
    "| a / b | a除以b |\n",
    "| a // b | a除以b后向下取整，丢弃小数部分 |\n",
    "| a ** b | a的b次方 |\n",
    "| a % b | 取余 |\n",
    "| -a | 负a |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 字符串的格式化输出`format()`。需要填充的地方用`{}`占位。\n",
    "\n",
    "`<模板字符串>.format(<逗号分隔的参数>)`\n",
    "\n",
    "![1-7](img/1-7.png)\n",
    "![1-8](img/1-8.png)\n",
    "\n",
    "- 对于 **数字格式化** ，模板字符串的占位槽除了包括参数序号，还可以包括格式控制信息，如`{<参数序号>: <格式控制标记>}`。其中，格式控制标记用来控制参数显示时的格式。格式控制标记包括：<填充><对齐><宽度><,><.精度><类型>6个字段，这些字段都是可选的，可以组合使用。\n",
    "\n",
    "![1-9](img/1-9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{0:+.2f} - {1:x<4d} + {2:_^10d} - {3:,}\".format(3.1415, 8, 8, 100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本数据结构\n",
    "- 包括列表（list）、元组（tuple）、字典（dict）、集合（set）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 列表（list）是一个有序的序列结构，序列中的元素可以是不同的数据类型。列表可以进行一系列序列操作，如索引、切片、加、乘和检查成员等。\n",
    "\n",
    "- 与大多数编程语言相同，Python列表（数组等）下标从0开始，而R语言和Matlab的数组下标从1开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''initialize a list'''\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''列表索引与切片'''\n",
    "print(planets[0])\n",
    "print(planets[-3])\n",
    "print(planets[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''一些相关函数'''\n",
    "print(len(planets))\n",
    "print(sorted(planets))\n",
    "print(sum([1,2,3,4,5]))\n",
    "print(min([5,3,2,6,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''一些相关方法'''\n",
    "planets.append('Pluto')\n",
    "print(planets)\n",
    "\n",
    "print(planets.pop())  # .pop() 默认删除并返回列表最后一个元素\n",
    "print(planets)\n",
    "\n",
    "print(planets.insert(0, 'Sun'))\n",
    "print(planets)\n",
    "\n",
    "print(planets.index('Earth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''改变列表的值'''\n",
    "planets[3:-3] = ['M', 'J', 'S']\n",
    "print(planets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **元组（tuple）** 基本上与列表相同，但：\n",
    "  - 使用小括号来创建。\n",
    "  - 元组一旦创建之后，不可变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **字典（dict）** 是一种大小可变的键值对（key - value）集，键和值都是Python对象。\n",
    "\n",
    "- 字典中的数据元素是无序的，不会按初始化时的顺序排列。可以多个键对应相同的值，但键必须是唯一的。键必须不可变，所以可以用数字，字符串或元组充当，而用列表就不行。\n",
    "\n",
    "![pydict](img/py-dict-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''初始化一个dict'''\n",
    "planets_dict = {'Mercury': 'M', 'Venus': 'V', 'Earth': 'E', 'Mars': 'M', 'Jupiter': 'J', 'Saturn': 'S', 'Uranus': 'U', 'Neptune': 'N'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''字典的查询、新增'''\n",
    "print(planets_dict['Mars'])\n",
    "planets_dict['Pluto'] = 'P'\n",
    "print(planets_dict)\n",
    "del planets_dict['Pluto']\n",
    "print(planets_dict)\n",
    "'''字典更新'''\n",
    "planets_dict.update({'Pluto':'P'})\n",
    "print(planets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''字典的一些常用方法'''\n",
    "print(planets_dict.items()) # k-v pairs\n",
    "print(planets_dict.keys())\n",
    "print(planets_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上返回的字典对象都是可迭代对象（iterable），也可以用`list()`函数转化为列表使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **集合（set）** 是一个无序的不重复元素序列。可以使用`{value01, value02, ...}`或`set()`函数创建，但空集合必须用`set()`创建。\n",
    "\n",
    "- 集合用法与列表类似，但也有一些独有的方法和特性，可以课后自行查阅。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循环与控制语句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 之前我们已经介绍了布尔型变量。Python的比较运算符有6种，逻辑运算符3种`or` `and` 和 `not`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 运算 | 说明 |\n",
    "| -- | -- |\n",
    "| a == b | 等于 |\n",
    "| a != b | 不等于 |\n",
    "| a < b | 小于 |\n",
    "| a <= b | 小于等于 |\n",
    "| a > b | 大于 |\n",
    "| a >= b | 大于等于 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if-else 条件判断\n",
    "- Python没有switch-case多分支选择（可以写一堆if-else或用字典映射来实现）。基本结构是（<font color=red>注意缩进</font>）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONDITION_1:\n",
    "    EXPRESSION_1\n",
    "elif CONDITION_2:\n",
    "    EXPRESSION_2\n",
    "else:\n",
    "    EXPRESSION_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for VARIABLES in ITERABLE:\n",
    "    EXPRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 列表、字典、集合都支持如下的 **推导式** 方式创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''列表的一种初始化方式'''\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "planets_short = [planet[:3] for planet in planets]\n",
    "planets_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''字典的一种初始化方式'''\n",
    "'''enumerate函数'''\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "planets_short_d = {ip:planet[:3] for ip, planet in enumerate(planets)}\n",
    "planets_short_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### while循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while CONDITION:\n",
    "    EXPRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数、模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数\n",
    "- Python函数的基本结构如下：\n",
    "\n",
    "![1-5](img/1-5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数传入支持顺序传入、关键词传入、默认参数和不定长参数。需要注意的是：\n",
    "  - 如果传入的第一个参数是用关键词传入的，那么后面每个参数都需要是关键词传入。\n",
    "  - 在定义和调用函数时，默认参数必须放到参数列表的末位。\n",
    "  \n",
    "- 不定长参数：为了解决不确定需要传入参数个数的情况\n",
    "  - 使用`*args`传入参数列表。\n",
    "  - 使用`**kwargs`传入参数字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个多项式函数\n",
    "def polynomial(x, y, z, w=-1):\n",
    "    s = 1 + 2*x + 3*y^2 + 4*z*w\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(polynomial(1,2,3))\n",
    "print(polynomial(1,y=2,z=3))\n",
    "print(polynomial(1,y=2,z=3,w=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''不定长参数：传入列表'''\n",
    "'''函数可以没有返回值'''\n",
    "def showListArgs(*args):\n",
    "    for i in args:\n",
    "        print(i)\n",
    "        \n",
    "showListArgs(*[5,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''不定长参数：传入字典'''\n",
    "'''多个返回值如果没有赋值给等数量的变量，则会打包为一个tuple输出'''\n",
    "def showDictArgs(**kwargs):\n",
    "    return list(kwargs.keys()), list(kwargs.values())\n",
    "\n",
    "print(showDictArgs(**{'1':2,'3':4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lambda表达式** ：简化的函数定义方式。Python灵活性的体现。\n",
    "\n",
    "![1-6](img/1-6.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial2 = lambda x,y,z,w=-1: 1 + 2*x + 3*y^2 + 4*z*w\n",
    "\n",
    "print(polynomial2(1,2,3))\n",
    "print(polynomial2(1,y=2,z=3))\n",
    "print(polynomial2(1,y=2,z=3,w=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块\n",
    "- 模块是Python中的最高级别组织单元，它将程序代码和数据封装起来以便重用。模块的三个角色：\n",
    "  - 代码重用。\n",
    "  - 系统命名空间的划分（模块可理解为变量名的封装，即模块就是命名空间）。\n",
    "  - 实现共享服务和数据。\n",
    " \n",
    "![1-10](img/1-10.jpg)\n",
    "\n",
    "![1-11](img/1-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模块的导入方式：\n",
    "  - `import xxxxx (as XXXXX)`\n",
    "  - `from xxxxx import *`\n",
    "  - `from xxxxx import yyyyy,zzzzz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas库基础\n",
    "- 前置技能：Python入门\n",
    "- Pandas [文档](https://pandas.pydata.org/docs/) 是目前最流行的用于数据分析的Python库之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2-1](img/2-1.png)\n",
    "\n",
    "**广义的数据分析包括狭义数据分析和数据挖掘。**\n",
    "\n",
    "- **狭义的数据分析** 是指根据分析目的，采用对比分析、分组分析、交叉分析和回归分析等分析方法，对收集来的数据进行处理与分析，提取有价值的信息，发挥数据的作用，得到一个特征统计量结果的过程。\n",
    "\n",
    "- **数据挖掘** 则是从大量的、不完全的、有噪声的、模糊的、随机的实际应用数据中，通过应用聚类、分类、回归和关联规则等技术，挖掘潜在价值的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 典型流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2-2](img/2-2.png)\n",
    "\n",
    "- **需求分析** ：数据分析中的需求分析也是数据分析环节的第一步和最重要的步骤之一，决定了后续的分析的方向、方法。\n",
    "- **数据获取** ：数据是数据分析工作的基础，是指根据需求分析的结果提取，收集数据。\n",
    "- **数据预处理** ：数据预处理是指对数据进行数据合并，数据清洗，数据变换和数据标准化，数据变换后使得整体数据变为干净整齐，可以直接用于分析建模这一过程的总称。\n",
    "- **分析与建模** ：分析与建模是指通过对比分析、分组分析、交叉分析、回归分析等分析方法和聚类、分类、关联规则、智能推荐等模型与算法发现数据中的有价值信息，并得出结论的过程。\n",
    "- **模型评价与优化** ：模型评价是指对已经建立的一个或多个模型，根据其模型的类别，使用不同的指标评价其性能优劣的过程。\n",
    "- **部署** ：部署是指将通过了正式应用数据分析结果与结论应用至实际生产系统的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2-3](img/2-3.jpg)\n",
    "\n",
    "以**设备管理**场景为例：通过物联网技术能够收集和分析设备上的数据流，包括连续用电、零部件温度、环境湿度和污染物颗粒等无数潜在特征，建立设备管理模型，从而预测设备故障，合理安排预防性的维护，以确保设备正常作业，降低因设备故障带来的安全风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''先加载pandas库'''\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建和读写文件\n",
    "- Pandas中有两种最为核心的对象：\n",
    "<font color=red>DataFrame（数据框）</font>\n",
    "和\n",
    "<font color=red>Series（数据序列）</font>\n",
    "。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据框（DataFrame）**\n",
    "\n",
    "数据框像一张Excel表格，表格中的数据可以是数值、字符串等类型。我们用\n",
    "<font color=green>pd.DataFrame()</font>\n",
    "来构造数据框。\n",
    "\n",
    "注意到构造数据框时，记录是以字典方式组织的，字典的key即为数据框的列名，字典的value可以是一个列表，其中的每一个元素都是该列的一条数据。\n",
    "\n",
    "数据框的每一行也有索引（**index**），默认是从0开始的整数，但也可以在构造数据框时用\n",
    "<code>index=</code>\n",
    "参数指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Yes': [50, 21], 'No': [131, 2], 'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Yes': [50, 21], 'No': [131, 2], 'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']},\n",
    "            index=['Product A', 'Product B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据序列（Series）**\n",
    "\n",
    "数据序列像Python的列表，是一系列数值。\n",
    "\n",
    "数据序列是数据框的一列，因此也可以指定索引参数。但数据序列没有列名，只有一个整体的名称，通过参数\n",
    "<code>name</code>\n",
    "设置。\n",
    "\n",
    "此外，也可以将数据框视为一组“粘在一起”的数据序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1888, 2888, 888], index=['2015-Sales', '2016-Sales', '2017-Sales'], name='Product A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 常见的数据会以\n",
    "<code>.csv</code>\n",
    "或\n",
    "<code>.xlsx</code>\n",
    "<code>.xls</code>\n",
    "格式存储。我们可以使用\n",
    "<font color=green>pd.read_csv()</font>\n",
    "或\n",
    "<font color=green>pd.read_excel()</font>\n",
    "函数进行读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslides = pd.read_csv(\"data/landslides-events_catalog.csv\")\n",
    "# 查看数据框大小\n",
    "print(landslides.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以用如下方式查看数据框的前n行'''\n",
    "landslides.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''用如下方式查看数据框的最后n行'''\n",
    "landslides.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们可以使用`pd.to_csv()`或`pd.to_excel()`函数将数据框存储到文件。\n",
    "\n",
    "Pandas在读入数据框时，会自动增加行索引，可以使用\n",
    "<code>index_col=0</code>\n",
    "参数使用数据文件的第一列作为行索引。存储文件时如果想忽略数据框的行索引（通常会新增一列），可以使用\n",
    "<code>index=False</code>\n",
    "参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslides.to_excel('data/landslides-events_catalog.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据框索引、筛选与赋值\n",
    "- 本节数据 [红酒评审](https://www.kaggle.com/zynicide/wine-reviews)\n",
    "\n",
    "\n",
    "- 先载入数据并查看数据概况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.read_csv(\"data/winemag-data-130k-v2_sample.csv\")\n",
    "pd.set_option('max_rows', 10)\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''获取数据框的行索引'''\n",
    "reviews.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''获取数据框列名'''\n",
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查看数据框中数据类型为数值（如float64/int64）的列的描述性统计'''\n",
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pandas库使用 **dtype** 表示数据框或数据序列的数据类型，如float64(64位浮点数)、int64(64位整数)等，而完全由字符串组成的列的数据类型则是object。可以用`reviews.price.dtype`或`reviews.index.dtype`查看数据框某一列或行索引的数据类型，也可以用`reviews.dtypes`获得所有列的数据类型，还可以用`astype()`方法转换某一列的数据类型，如`reviews.points.astype('float64')`。同学们可以在下面的代码框中自行试验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''（请开始你的表演）'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 那么该如何引用数据？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pandas支持以对象的方式访问一列'''\n",
    "reviews.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查看该列的描述性统计'''\n",
    "reviews.country.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也支持以字典方式访问某一列'''\n",
    "'''通常这种方式适用范围更广，比如列名中包含空格的情况'''\n",
    "reviews['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''访问某列中的某个“单元格”'''\n",
    "reviews['country'][987]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 访问数据框中的数据： **对某一列的某几行访问** ：返回数据序列对象。 **对多列数据访问** ：返回数据框对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 以`.loc`或`.iloc`方式访问数据。\n",
    "> - `.loc`方法：传入索引名称。`.loc[行索引名称或条件, 列索引名称]`\n",
    "> - `.iloc`方法：传入索引编号数值。`.iloc[行索引编号, 列索引编号]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''提取country和taster_name列'''\n",
    "reviews.loc[[1,3,5,7,9], ['country', 'taster_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''提取第5和9列'''\n",
    "'''注意与.loc方法相比，行索引的开闭区间不同'''\n",
    "reviews.iloc[202:216, [5, 9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 根据条件筛选数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们可以从如下语句开始'''\n",
    "reviews.country == 'Italy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述操作会产生一列对应每条记录的布尔值True/False。这一结果可以用于`.loc`和`.iloc`索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 5) # 先设置展示记录条数\n",
    "reviews.loc[reviews.country == 'Italy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以添加多个筛选条件，用()包住'''\n",
    "reviews.loc[(reviews.country == 'Italy') & (reviews.points >= 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''选择多个国家'''\n",
    "reviews.loc[(reviews.country == 'Italy') | (reviews.country == 'France')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pandas内置了一些条件筛选器，下面以`.isin()`，`.notnull()` / `.isnull()`和`.str.contains()`为例进行介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''上述筛选多个国家的条件可以写成'''\n",
    "reviews.loc[reviews.country.isin(['Italy', 'France'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''isnull()和notnull()用来判断空/非空值'''\n",
    "'''例如查看“不要钱”的红酒的评价'''\n",
    "reviews.loc[reviews.price.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''模糊筛选数据，类似于SQL语句中的LIKE，可以使用正则表达式'''\n",
    "reviews[reviews['description'].str.contains(r'.*?rich.*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据框的赋值也比较简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''赋固定值'''\n",
    "reviews['new_column'] = 'everyone'\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''以可迭代对象赋值'''\n",
    "'''需要注意可迭代对象的长度要和dataframe.index相同'''\n",
    "reviews['new_column'] = range(len(reviews), 0, -1)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用`.rename()`方法可以更改行/列索引的名字\n",
    "\n",
    "- 通过指定`index=` / `columns=`来指定是对行/列索引进行修改，支持多种传参格式，但字典最常用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''例如将points列改为score'''\n",
    "reviews.rename(columns={'points': 'score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''再更改一下行索引'''\n",
    "reviews.rename(index={0: 'firstEntry', 1: 'secondEntry'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据框映射\n",
    "- **映射** 与数学中的概念类似，可以将一组值映射到另一组值。在数据科学中，我们经常需要对现有的值进行一些运算、变换、格式转换等操作，此时映射函数就能派上用场，而不需要每次都写for循环来完成。\n",
    "\n",
    "\n",
    "- `.map()`是第一种常用的映射方法，可作用于数据序列（Series）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 10)\n",
    "'''可以传入一个映射字典'''\n",
    "print(reviews.country)\n",
    "print(reviews.country.map({'US':'USofA'})) # 不在映射字典里的数据会被映射为NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以传入一个表达式（lambda函数），比如开根号再乘10'''\n",
    "import numpy as np\n",
    "reviews.points.map(lambda p: np.sqrt(p)*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.apply()`是相对复杂一些的方法，它可作用于数据框和数据序列。可以使用`axis=`参数指定作用于行或列（传入值可以是0/1，index/columns）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''比如我们构建如下开根号乘10函数'''\n",
    "def multiply_sqrt_by_ten(row):\n",
    "    row['points'] = np.sqrt(row['points']) * 10\n",
    "    return row\n",
    "\n",
    "reviews.apply(multiply_sqrt_by_ten, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应当注意的是，以上所有对数据框的操作（除了对数据框赋值，新增了一列）都没有改变原有数据框，而是返回了新的数据框。我们可以将操作返回结果赋值给一个新变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查看第一行，发现原数据确实没有变化'''\n",
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据框分组、排序\n",
    "- `.groupby()`方法可以对数据进行分组。分组方法输出的结果是一个与Series/Dataframe类似的对象`pandas.core.groupby.generic.DataFrameGroupBy`，也可以使用一些数据序列/数据框的方法。\n",
    "\n",
    "- 有效使用`.groupby()`方法可以极大提升数据分析效率，推荐同学们结合 [文档](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) 多加实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 20)\n",
    "print(type(reviews.groupby('points')))\n",
    "'''按评价得分分组，并查看每组记录数'''\n",
    "reviews.groupby('points').points.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以apply一个lambda表达式'''\n",
    "'''看一下每个分数的分组里价格最贵的酒来自哪个国家'''\n",
    "reviews.groupby('points').apply(lambda df: df.country.loc[df.price.idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以按多列分组'''\n",
    "reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我们发现使用多列分组后输出的数据框会生成 **多重索引** ，对象类型是`pandas.core.indexes.multi.MultiIndex`。Pandas提供了一些处理多重索引的方法，而且在行检索时，需要多个级别的标签才能定位到值，对入门用户来说并不友好，具体可以查看Pandas文档中的[MultiIndex/Advanced Selection](https://pandas.pydata.org/pandas-docs/stable/advanced.html)部分。但在通常情况下，我们可以使用`.reset_index()`方法将多重索引重新转换回常规索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_grouped = reviews.groupby(['country', 'province']).description.agg([len])\n",
    "countries_grouped.columns = ['NumOfRecords']\n",
    "countries_grouped = countries_grouped.reset_index()\n",
    "countries_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `.groupby()`方法的输出结果是按行索引排序的，我们以`countres_grouped`为例，进行一些用值排序的操作，包括`.sort_values()` 和 `.sort_index()`方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''按NumOfRecords排序，ascending=True/False表示递增/递减'''\n",
    "countries_grouped.sort_values(by='NumOfRecords', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以用行索引排序，入参与.sort_values()相同'''\n",
    "countries_grouped.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''.sort_values()支持按多列排序'''\n",
    "countries_grouped.sort_values(by=['country', 'NumOfRecords'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据框合并\n",
    "- Pandas数据框合并主要有三种方式：\n",
    "  - 直接复制合并。\n",
    "  - 拼接方法：`.append()` / `pd.concat()`方法。\n",
    "    - `.append()`专门用于在表尾追加数据。\n",
    "    - `pd.concat()`可以控制是横向拼接还是纵向拼接，`join=`参数控制交集/并集。`axis=`参数控制列/行方向拼接。\n",
    "  - 主键合并：`.join()` / `pd.merge()`方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''直接合并'''\n",
    "'''按行索引对齐，不会给原数据增加新行。合并进来的新数据会有丢失风险'''\n",
    "data0 = pd.DataFrame({'A':[1,2,3], 'B':[2,3,4]})\n",
    "data1 = pd.DataFrame({'C':[5,4,3], 'D':[8,7,6]}, index=[1,2,3])\n",
    "data0[['c','d']] = data1[['C','D']]\n",
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''先读2个iris（鸢尾花）数据'''\n",
    "iris_set_data = pd.read_csv('data/iris_setosa.csv')\n",
    "iris_vir_data = pd.read_csv('data/iris_virginica.csv')\n",
    "iris_vir_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .append()追加方法\n",
    "'''ignore_index=False/True用于控制是/否保留2个数据框原有的索引号'''\n",
    "iris_set_data.append(iris_vir_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''用pd.concat进行横向合并，即使列名相同，也不会合并成一列'''\n",
    "pd.concat([iris_set_data, iris_vir_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 主键合并，即通过一个或多个键将两个数据集的行连接起来，类似于SQL中的JOIN。针对同一个主键存在两张包含不同字段的表，将其根据某几个字段一一对应拼接起来，结果集列数为两个元数据的列数和减去连接键的数量。\n",
    "\n",
    "![2-5](img/2-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''主键合并，以join()为例'''\n",
    "iris_set_data.join(iris_vir_data, lsuffix='_SET', rsuffix='_VIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''主键合并，以pd.merge()为例'''\n",
    "pd.merge(iris_set_data, iris_vir_data, suffixes=('_SET', '_VIR'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用Pandas库进行数据清洗\n",
    "- 前置技能：Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据清洗（Data Cleaning）是数据科学的一个关键部分。在数据处理过程中，我们常常会碰到以下问题：为什么一些文本是乱码？为什么日期格式不正确？应该如何处理缺失值？以下内容会带你了解如何处理一些最常见的数据清理问题，以便能够更快地实际分析数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理缺失值\n",
    "- 首先载入练习所需的库和数据，我们使用 [NFL play-by-play 2016](https://www.kaggle.com/imnickschroeder/nfl-playbyplay-2016) 数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nfl_data = pd.read_csv(\"data/NFL Play by Play 2009-2017 (v4) sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当你拿到一个新的数据集时，首先要做的是查看其中一些数据，这样可以检查数据是否都正确的被读入，并且了解一些数据的基本情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查看前10条数据'''\n",
    "nfl_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''获取并查看每一列的缺失数据个数'''\n",
    "missing_value_count = nfl_data.isnull().sum()\n",
    "print(missing_value_count[0:10]) # 这里选择查看前10列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''缺失数据占总数据的百分比'''\n",
    "total_cells = np.product(nfl_data.shape)\n",
    "total_missing = missing_value_count.sum()\n",
    "\n",
    "percent_missing = round((total_missing/total_cells) * 100, 3)\n",
    "print(percent_missing, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在做数据清理前，我们需要\n",
    "<font color=red>找出数据丢失的原因</font>\n",
    "，即弄清楚\n",
    "<font color=red>这个值丢失是因为它没有被记录还是因为它不存在？</font>\n",
    "因为这会影响我们未来的数据分析思路。\n",
    "\n",
    "\n",
    "- 这也是数据科学一个充满挑战的地方，特别是面对一些来自我们不了解的新领域的数据。此时我们可以寻求一些帮助：\n",
    "  - 查看数据文档\n",
    "  - 询问该领域有经验的人士，或者询问向你提供数据的人\n",
    "  - 依靠以前处理数据的部分经验\n",
    "\n",
    "\n",
    "- 如果某个值因为不存在而丢失（比如某个没车的人，目前名下最贵的车多少钱），那么尝试猜测它可能是什么就没有意义了，我们可以将这些值保留为NaN。另一方面，如果一个值因为没有被记录而丢失，那么我们可以尝试根据该列和行中的其他值来猜测它可能是什么，这就是所谓的插补。\n",
    "\n",
    "\n",
    "- 例如，从[文档](https://github.com/maksimhorowitz/nflscrapR/blob/master/man/game_play_by_play.Rd)中我们获知\n",
    "<font color=red>TimeSecs</font>\n",
    "这一列是关于游戏进行时游戏剩余秒数的信息（Time remaining in game in seconds）。这意味着这一列中丢失的值是因为它们没有被记录，而不是因为它们不存在。所以，我们可以试着去猜测它们应该是什么，而不是仅仅把它们当作NaN。\n",
    "\n",
    "\n",
    "- 再比如\n",
    "<font color=red>PenalizedTeam</font>\n",
    "这一列表示比赛中被处罚的队伍（The penalized team on the play），也有很多缺失的字段。然而如果一场比赛中没有球队被处罚，那么这个值是没有意义的，可以将其保留为空或使用第三个值（如“没有”、“无”）并使用该值替换NA则更为合理。\n",
    "\n",
    "\n",
    "- 对于特定的数据分析案例，我们最好能够逐个查看每一列，结合数据的属性和特征，找出填补这些缺失值的最佳策略。但本文档将会介绍一些普适的、“quick and dirty”的技术帮助我们处理丢失的值，但最终可能会删除一些有用的信息或给数据添加一些噪音。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 丢弃（drop）缺失值**\n",
    "\n",
    "\n",
    "如果时间紧急或者没有找出导致数据缺失的原因，我们可以选择删除包含缺失值的任何行或列。\n",
    "<font color=red>对于重要项目，一般不推荐这种方法！花点时间浏览数据，逐个查看所有缺少值的列，以便真正了解数据集，这通常是值得的。</font>\n",
    "如果确定要删除缺少值的行，可以使用函数`dropna()`来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完蛋！我们把所有数据都删了！因为数据集里的每一行都至少缺失一个值。那我们转换一下思路，\n",
    "<font color=red>把包含至少一个缺失值的列都删掉</font>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''可以看到包含缺失值的列都消失了'''\n",
    "columns_with_na_dropped = nfl_data.dropna(axis=1) # axis=1 按列；axis=0 按行\n",
    "columns_with_na_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''经过一番操作，我们还剩多少数据？'''\n",
    "print(\"还剩 {0}% 数据\".format(str(round(100*(np.product(columns_with_na_dropped.shape)/np.product(nfl_data.shape)),3))))\n",
    "print(\"还剩 {0}/{1} 列数据\".format(columns_with_na_dropped.shape[1], nfl_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>虽然我们丢失了将近60%的数据，但我们没有NaN值了呀！</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 自动填充（fill-in）缺失值**\n",
    "\n",
    "\n",
    "除了丢弃缺失数据，我们还可以尝试填充缺失值。使用\n",
    "<font color=green>fillna()</font>\n",
    "函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 取一小部分数据\n",
    "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
    "subset_nfl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''可以直接用某个固定值来替换掉所有缺失值'''\n",
    "'''这个固定值可以是数值，也可以是字符串'''\n",
    "subset_nfl_data.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以采取某些填充策略，比如在同一列中，用后面直接出现的值替换缺失的值。（这对于观测具有某种逻辑顺序的数据集很有意义。）'''\n",
    "subset_nfl_data.fillna(method='bfill', axis=0).fillna(-999) # 先用后面出现的值替换，再用-999替换剩下的NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fillna()`函数的method包含以下两种选择：\n",
    "  - <font color=#CE0000>backfill/bfill</font>: 用下一个非缺失值填充该缺失值\n",
    "  - <font color=#CE0000>pad/ffill</font>: 用前一个非缺失值填充该缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_nfl_data.fillna(method='ffill', axis=0).fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据缩放：归一化与标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据缩放，在统计学中的意思是，通过一定的数学变换方式，将原始数据按照一定的比例进行转换，将数据放到一个小的特定区间内，比如\\[0,1\\]或者\\[-1,1\\]。目的是消除不同样本之间特性、数量级等特征属性的差异，转化为一个无量纲的相对数值，结果的各个样本特征量数值都处于同一数量级上。\n",
    "\n",
    "\n",
    "- 数据归一化或标准化时，都需要转换数值变量的值，以便转换后的数据点具有特定的有用属性。区别在于：\n",
    "  - 数据归一化主要是数据范围上的变化\n",
    "  - 数据标准化改变数据的分布情况，通常转变为正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''首先加载需要的库'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "# 数据可视化\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当用到数据间的距离、相似度等度量时，归一化起到重要作用，如机器学习算法中的支持向量机（SVM）和K近邻（KNN）。归一化前后数据分布\n",
    "<font color=red>不变</font>\n",
    "。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按指数分布随机生成1000个数据点\n",
    "original_data = np.random.exponential(size=1000)\n",
    "\n",
    "'''使用min-max归一化方法/极差法'''\n",
    "scaled_data = minmax_scaling(original_data, columns=[0])\n",
    "\n",
    "# 画前后结果进行对比\n",
    "fig, ax = plt.subplots(1,2)\n",
    "sns.distplot(original_data, ax=ax[0])\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.distplot(scaled_data, ax=ax[1])\n",
    "ax[1].set_title(\"Scaled data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当算法要求数据满足正态分布时，则需要对原始数据进行标准化操作，如线性判别器（LDA）和高斯朴素贝叶斯（Gaussian naive Bayes）算法假设数据符合正态分布。标准化前后数据分布\n",
    "<font color=red>可能改变</font>\n",
    "。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''使用box-cox变换对原始数据进行标准化操作'''\n",
    "normalized_data = stats.boxcox(original_data)\n",
    "\n",
    "# 画前后结果进行对比\n",
    "fig, ax=plt.subplots(1,2)\n",
    "sns.distplot(original_data, ax=ax[0])\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.distplot(normalized_data[0], ax=ax[1])\n",
    "ax[1].set_title(\"Normalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日期格式数据解析\n",
    "- 本节数据 [2007-2016全球雨后滑坡数据集](https://www.kaggle.com/nasa/landslide-events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''首先加载需要的库和数据'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns # 数据可视化\n",
    "import datetime # python的日期/时间库\n",
    "\n",
    "landslides = pd.read_csv(\"data/landslides-events_catalog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''先检查一下日期格式'''\n",
    "print(landslides['date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这些数据可以被人类判断为日期，但对于Python来说则未必。注意这里dtype是object，Pandas使用object数据类型来存储各种类型的数据类型，但是通常当我们看到一个数据类型为object的列时，其中会包含字符串类型数据。\n",
    "\n",
    "\n",
    "- Pandas的[dtype](http://pandas.pydata.org/pandas-docs/stable/basics.html\\dtypes)文档中有一个特定的日期格式数据类型datetime64，很明显Python不知道我们的date数据列包含日期。\n",
    "\n",
    "\n",
    "- 我们也可以使用如下命令检查本列数据的类型，参考[numpy dtype](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind)文档，也可以知道本列数据为object（\n",
    "<font color=red>dtype('0')</font>\n",
    "）类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslides['date'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在我们开始将以字符串形式的日期、时间数据解析为Python可以识别的日期/时间数据。\n",
    "\n",
    "\n",
    "- 参考 [strftime](http://strftime.org/)文档给出的信息，基本思想是我们需要指出\n",
    "<font color=red>日期的哪些部分在哪里</font>\n",
    "，以及\n",
    "<font color=red>这些部分之间是用什么标点符号分隔的</font>\n",
    "。\n",
    "\n",
    "\n",
    "- 例如，最常见的是\n",
    "<font color=#CE0000>%d</font>代表日，\n",
    "<font color=#CE0000>%m</font>代表月，\n",
    "<font color=#CE0000>%y</font>代表两位数年，\n",
    "<font color=#CE0000>%Y</font>代表四位数年，如：\n",
    "  - 1/17/07的格式为<font color=#CE0000>%m/%d/%y</font>\n",
    "  - 17-1-2007的格式为<font color=#CE0000>%d-%m-%Y</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "那我们可以用%m/%d/%y的格式解析我们数据集里的date列\n",
    "新建date_parsed列，存储解析后的日期数据\n",
    "\n",
    "查看新的列，发现数据类型为datetime64，并且年/月/日的顺序有些许变化\n",
    "'''\n",
    "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format=\"%m/%d/%y\")\n",
    "print(landslides['date_parsed'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 需要注意的是，如果同一列数据中包含多种日期格式，可以让Pandas推断正确的日期格式是什么，参考如下代码：\n",
    "\n",
    "<code>landslides['date_parsed'] = pd.to_datetime(landslides['date'], infer_datetime_format=True)</code>\n",
    "\n",
    "\n",
    "- 但不建议总使用<code>infer_datetime_format=True</code>这个参数，因为：\n",
    "  - 如果日期格式的自定义程度过高，Pandas也不能准确识别\n",
    "  - 这种方法的处理速度比指定日期格式要慢得多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "基于已经处理好的日期数据，我们可以把“每个月的第几日”提取出来\n",
    "'''\n",
    "day_of_month_landslides = landslides['date_parsed'].dt.day\n",
    "day_of_month_landslides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果我们希望从<code>landslides['date']</code>列中提取同样的数据，则会发生错误\n",
    "<code>AttributeError: Can only use .dt accessor with datetimelike values</code>\n",
    "这是因为即使包含日期信息，<code>dt.day</code>也无法处理object类型的数据。\n",
    "\n",
    "\n",
    "\n",
    "- 解析日期的最大风险点是混淆了月份和日期。虽然`to_datetime()`函数确实比较靠谱，但我们也可以再画个图来检查一下处理结果。比如我们可以画一个月内每天滑坡发生次数的柱状图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先去掉所有的NaN值（听起来是不是很熟悉）\n",
    "day_of_month_landslides = day_of_month_landslides.dropna()\n",
    "\n",
    "# 再用seaborn库画柱状图，分31个bins（因为每个月的天数在1-31范围内）\n",
    "sns.distplot(day_of_month_landslides, kde=False, bins=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符编码问题\n",
    "- 本节我们将了解字符编码相关的问题。\n",
    "\n",
    "**什么是编码(encodings)？**\n",
    "\n",
    "**字符编码(character encodings)** 是将字符串从原始二进制字节（如01101001001）映射到构成人类可读文本的字符（如\"a\"）的特定规则集。如果试图用不同于字符串本身编码的方式来阅读文本，则会出现我们非常熟悉的\n",
    "<font color=red>乱码</font>，比如：\n",
    "  - <font color=red>烫烫烫屯屯屯</font>: Windows平台下VC编译器将未初始化的内存填成0xCC和0xCD，在简体中文Windows的CP936编码环境中显示出的乱码\n",
    "  - <font color=red>锟斤拷</font>: Unicode字符集占位符在GBK/GB2312/GB18030编码环境中显示成的一系列乱码\n",
    "  - <font color=red>����������</font>: 用来读入字节串的编码中的某个字节和字符集中的字符没有映射时出现\n",
    "  \n",
    " \n",
    "Python主要使用\n",
    "<font color=red>UTF-8</font>\n",
    "编码，UTF-8是标准文本编码，所有Python代码都是UTF-8格式，在理想情况下，所有数据也都应该是UTF-8格式。\n",
    "\n",
    "\n",
    "Python3相比Python2处理编码要简单很多。在Python3中处理文本时，主要会碰到两种数据类型。其一是字符串，默认情况下文本都以字符串类型保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个字符串\n",
    "before = \"This is the 人民币 symbol: ¥\"\n",
    "\n",
    "# 查看字符串类型\n",
    "type(before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其二是 [字节串 bytes](https://docs.python.org/3/library/stdtypes.html?highlight=bytes#bytes) 类型，这是一个整数序列。通过指定字符集（编码方式），可以将字符串转化为字节串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将字符串转化为字节串\n",
    "after = before.encode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "# 查看类型\n",
    "type(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果查看一个bytes对象，我们会发现它以\n",
    "<font color=red>b</font>\n",
    "开头，后面可能会有一些文本。这些文本是将字节串转为ASCII编码后打印出来的，ASCII是一种较老的英语字符集，汉字和一些符号无法被ASCII字符集识别，就会出现如下一些乱码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看字节串\n",
    "after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''如果我们用正确的字符集去转换字节串，则会得到正确的结果'''\n",
    "print(after.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''如果我们使用错误的字符集去解码字节串，则会报错'''\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果我们尝试用错误的编码方式将字符串映射到字节串，也会碰到问题。例如，我们尝试使用`encode()`将字符串转换为ASCII字节串，我们也可以得到字节串输出。由于我们的文本不是ASCII格式，会有一些字符无法处理。我们可以通过设置参数来自动替换这些ASCII无法处理的字符，以避免程序报错，但这种情况下，任何不在ASCII中的字符都将被替换为未知字符。当我们把字节串转回字符串后，这些字符将变为未知字符。\n",
    "<font color=red>这将导致数据的缺失，是非常危险的。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = \"This is the 人民币 symbol: ¥\"\n",
    "\n",
    "# 使用错误的编码方式转换字符串\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# 再将字节串转为字符串\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 因此最好能在最开始处理数据时就将文本内容统一转换为UTF-8格式并保持。例如，在读入如下非UTF-8编码文件时，会报错："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv('data/1500_458_orgdata-1_RS1_RS2_cnt.csv')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们也不知道正确的编码是什么。解决这个问题的一个方法是尝试测试一堆不同的字符编码，比如中文常见的编码方式有GBK/GB2312/GB18030等。不过更好的方法可以用\n",
    "<font color=blue>chardet</font>\n",
    "模块尝试自动猜测正确的编码可能是什么，虽然这种方法也不是百分之百准确，但总比凭经验猜测要靠谱很多。我们只需要读取这个文件的开头一部分，这对于猜测编码来说已经足够了，而且比查看整个文件要快很多（特别是对于大文件）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "'''以二进制格式打开文件，并用前1000字节判断该文件的编码方式'''\n",
    "with open('data/1500_458_orgdata-1_RS1_RS2_cnt.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(1000))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在我们知道该文件有99%的概率是用\n",
    "<font color=red>GB2312</font>\n",
    "方式编码的，那么我们尝试打开文件，并将其保存为\n",
    "<font color=red>UTF-8</font>\n",
    "编码格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先以GB2312打开\n",
    "df = pd.read_csv('data/1500_458_orgdata-1_RS1_RS2_cnt.csv', encoding='GB2312')\n",
    "# 再用UTF-8保存\n",
    "df.to_csv('data/1500_458_orgdata-1_RS1_RS2_cnt_UTF8.csv', encoding='UTF-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入数据不一致问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "prof = pd.read_csv('data/pakistan_intellectual_capital.csv')\n",
    "prof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们以教师们的国籍信息为例'''\n",
    "countries = prof['Country'].unique()\n",
    "\n",
    "# 按首字母排序，并查看\n",
    "countries.sort()\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们可以发现一些常见的数据不一致问题，例如字符串开头/结尾处多余的空格、大小写不一致等，这些都是非常常见的问题。我们可以用如下的命令做一些修正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部转换为小写\n",
    "prof['Country'] = prof['Country'].str.lower()\n",
    "# 去除字符串开头/结尾处多余的空格\n",
    "prof['Country'] = prof['Country'].str.strip()\n",
    "# 再看一下结果\n",
    "countries_1 = prof['Country'].unique()\n",
    "countries_1.sort()\n",
    "print(countries_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 经过处理，我们还是发现了一些“更高级”的数据不一致问题，例如'south korea'和'southkorea'等等。对于小数据集，我们可以采用手工方法逐个处理，但用人工方式处理大数据集显然是不可接受的。接下来我们使用\n",
    "<font color=blue>fuzzywuzzy</font>\n",
    "库来进行模糊匹配。fuzzywuzzy会返回给定两个字符串的相似度比例，比例越接近100，这两个字符串间的编辑距离越小。\n",
    "\n",
    "> 模糊匹配（fuzzy matching）：自动查找与目标字符串非常相似的文本字符串的过程。\n",
    "\n",
    "> 编辑距离（Minimum Edit Distance，MED）：由俄罗斯科学家 Vladimir Levenshtein 在1965年提出，也因此而得名 Levenshtein Distance。在信息论、语言学和计算机科学领域，Levenshtein Distance 是用来度量两个序列相似程度的指标。通俗地来讲，编辑距离指的是在两个单词之间，由其中一个单词转换为另一个单词所需要的最少单字符编辑操作次数。其中单字符编辑操作有且仅有3种：插入、删除、替换。例如apple和snapple，in和on分别对应插入和替换。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "# 获取countries中与\"south korea\"最接近的5个匹配\n",
    "matches = process.extract(\"south korea\", countries_1, limit=5, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''这里我们可以定义一个函数来进行替换操作'''\n",
    "def replace_matches_in_column(dataframe, column, string_to_match, min_ratio=90, fuzzy_limit=10):\n",
    "    # 获得该列所有不重复字符串\n",
    "    strings = dataframe[column].unique()\n",
    "    # 获取strings中前fuzzy_limit个与string_to_match最接近的字符串\n",
    "    matches = process.extract(string_to_match, strings, limit=fuzzy_limit, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "    # 以min_ratio作为下限进行筛选\n",
    "    close_matches = [match[0] for match in matches if match[1] >= min_ratio]\n",
    "    # 获取dataframe中所有匹配到的行\n",
    "    rows_with_matches = dataframe[column].isin(close_matches)\n",
    "    # 替换\n",
    "    dataframe.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    return dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''现在我们进行替换'''\n",
    "targets = [('usa', 70), ('south korea', 45)]\n",
    "for t in targets:\n",
    "    prof = replace_matches_in_column(prof, column='Country', string_to_match=t[0], min_ratio=t[1], fuzzy_limit=5)\n",
    "\n",
    "# 看看结果\n",
    "countries_2 = prof['Country'].unique()\n",
    "countries_2.sort()\n",
    "print(countries_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn数据可视化\n",
    "- 数据可视化的形式根据不同的行业、专业、数据特征，可能会有非常大的差别。以大气科学为例，常用的可视化形式有风玫瑰图、垂直廓线图、地理位置分布图（如气温、降水等），而这些可视化形式在别的专业可能并不常用。因此，本章通过讲解一些常见的图表类型，仅能起到抛砖引玉的作用。除了更多功能、样式、参数的设置需要大家参考官方文档之外，具体的数据可视化形式还需要各位结合自己的专业、数据特点进行思考。\n",
    "\n",
    "\n",
    "- [Seaborn](http://seaborn.pydata.org/) 是基于Matplotlib的图形可视化Python包。它提供了一种高度交互式界面，便于用户能够做出各种有吸引力的统计图表。Seaborn在Matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，应该把Seaborn视为Matplotlib的补充，而不是替代物。同时它能高度兼容Numpy与Pandas数据结构以及Scipy等统计模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 折线图（line chart）\n",
    "- 本节使用的数据来自流媒体音乐服务平台Spotify，为以下5首流行歌曲的热度：\n",
    "  - <font color=blue>Shape of You</font> by Ed Sheeran\n",
    "  - <font color=blue>Despacito</font> by Luis Fonzi\n",
    "  - <font color=blue>Something Just Like This</font> by The Chainsmokers and Coldplay\n",
    "  - <font color=blue>HUMBLE</font> by Kendrick Lamar\n",
    "  - <font color=blue>Unforgettable</font> by French Montana\n",
    "  \n",
    "  \n",
    " 首先载入数据，并以`Date`列为索引，并自动识别日期字符串格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv('data/spotify.csv', index_col=\"Date\", parse_dates=True)\n",
    "'''查看前10行，发现后3列数据为NaN，因为当时这3首歌曲还未发行'''\n",
    "spotify_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''与head相对，可以用tail查看数据框最后n条数据'''\n",
    "'''5列数据都有值'''\n",
    "spotify_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们可以先简单画一个草图'''\n",
    "sns.lineplot(data=spotify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''再加亿点点细节'''\n",
    "# 给Seaborn设置中文字体\n",
    "sns.set(font_scale=1.4) # 字体缩放比例\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(14, 6)) # 设置画布大小，单位为英寸，宽 x 高\n",
    "plt.title(\"2017-2018年每日全球热度\") # 设置标题\n",
    "sns.lineplot(data=spotify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''如果只关心其中的几列数据'''\n",
    "'''比如只挑选Shape of You，Despacito和Unforgettable'''\n",
    "# 给Seaborn设置中文字体\n",
    "sns.set(font_scale=1.4) # 字体缩放比例\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(14, 6)) # 设置画布大小，单位为英寸，宽 x 高\n",
    "plt.title(\"2017-2018年每日全球热度\") # 设置标题\n",
    "\n",
    "'''可以一条一条画'''\n",
    "sns.lineplot(data=spotify_data['Shape of You'], label='Shape of You')\n",
    "sns.lineplot(data=spotify_data['Despacito'], label='Despacito')\n",
    "sns.lineplot(data=spotify_data['Unforgettable'], label='Unforgettable')\n",
    "\n",
    "plt.xlabel(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''也可以一起画'''\n",
    "plt.figure(figsize=(14, 6)) # 设置画布大小，单位为英寸，宽 x 高\n",
    "plt.title(\"2017-2018年每日全球热度\") # 设置标题\n",
    "sns.lineplot(data=spotify_data.loc[:, ['Shape of You', 'Despacito', 'Unforgettable']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条形图（bar chart）和热力图（heatmaps）\n",
    "- 本节使用的数据来自2015年美国交通部跟踪航班延误的数据集。每个数据代表不同航空公司（列）和月份（行）的平均到达延误时间（单位：分钟），负数表示提前到达。例如，美国航空公司（American Airlines，AA）1月份航班平均晚到约7分钟，而阿拉斯加航空公司（Alaska Airlines，AS）4月份航班平均提前3分钟到达。\n",
    "\n",
    "下面载入数据，并以月份`Month`为索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data = pd.read_csv('data/flight_delays.csv', index_col='Month')\n",
    "flight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''下面我们以精神（小伙）航空公司（Spirit Airlines，NK）的每月平均延误时间为例，画条形图'''\n",
    "'''\n",
    "精神航空公司是美国的廉价航空公司，经营整个美洲地区的定期航班。\n",
    "该航空公司的总部设在佛罗里达州迈阿密市区的美丽华。\n",
    "该航空公司目前维持的基地是佛罗里达州劳德代尔堡，密歇根州底特律以及新泽西州大西洋城。\n",
    "精神航空超过半数的航班飞往加勒比海，巴哈马，和拉丁美洲等目的地。\n",
    "'''\n",
    "# 给Seaborn设置中文字体\n",
    "sns.set(font_scale=1.4) # 字体缩放比例\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.title(\"精神航空公司（NK）月度平均航班延误时间\")\n",
    "\n",
    "sns.barplot(x=flight_data.index, y=flight_data['NK'])\n",
    "'''\n",
    "注意到这里x轴我们直接使用了flight_data数据框的索引，而不是flight_data['Month']列。\n",
    "这是由于我们在载入数据时选择了使用Month列作为索引，因此直接引用flight_data['Month']将会报错。\n",
    "'''\n",
    "\n",
    "plt.ylabel(\"平均延误时间（分钟）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们还可以通过绘制热力图来快速了解数据的分布情况'''\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.title(\"各航空公司月度航班延误时长\")\n",
    "\n",
    "sns.heatmap(data=flight_data, annot=True, square=True,\n",
    "           center=16, cbar=True, cmap='rainbow')\n",
    "\n",
    "plt.xlabel(\"航空公司\")\n",
    "plt.ylabel(\"月份\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 散点图（scatter plot）\n",
    "- 本节所用数据来自 [个人医疗保险数据集](https://www.kaggle.com/mirichoi0218/insurance/home)。本数据集包含年龄、性别、BMI、保险覆盖的儿童人数、是否吸烟、地区、费用这些列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = pd.read_csv('data/insurance.csv')\n",
    "insurance_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''画一张费用与BMI的散点图'''\n",
    "sns.set(font_scale=1.0)\n",
    "sns.scatterplot(x=insurance_data['bmi'], y=insurance_data['charges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上散点图表明，体重指数（BMI）与保险费用正相关，这很好理解，因为高BMI通常与更高的慢性病风险相关。\n",
    "\n",
    "\n",
    "- 通常我们会添加一条回归曲线来查看y-x之间的相关关系，可以用`sns.regplot`命令。参考阅读 [regplot参数讲解](https://cloud.tencent.com/developer/article/1517210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=insurance_data['bmi'], y=insurance_data['charges'], order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''通过为散点增加颜色信息，我们可以使用散点图来显示三个变量之间的关系。'''\n",
    "sns.scatterplot(x=insurance_data['bmi'], y=insurance_data['charges'], hue=insurance_data['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''使用lmplot命令为散点图添加回归线'''\n",
    "sns.lmplot(x=\"bmi\", y=\"charges\", hue=\"smoker\", data=insurance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''使用swarmplot命令绘制分类散点图'''\n",
    "sns.swarmplot(x=insurance_data['smoker'],\n",
    "              y=insurance_data['charges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些思考：\n",
    "  - 随着BMI增加，吸烟者、不吸烟者的保费都会增加，但吸烟者增加的速度明显快于不吸烟者。\n",
    "  - 平均而言，吸烟者的保费要高于不吸烟者。保费最高的人群基本都是吸烟者，而保费最低的人群基本都是不吸烟者。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分布图（distributions）\n",
    "- 本节使用鸢尾花（Iris）数据集。鸢尾花分为3类，分别为山鸢尾Iris-setosa，变色鸢尾Iris-versicolor和维吉尼亚鸢尾Iris-virginica，每种50条数据，共150条。\n",
    "\n",
    "- 每行数据表示一朵不同的花，包括花的种类、花萼（sepal）的长度和宽度、花瓣（petal）的长度和宽度共5列数据。\n",
    "\n",
    "参考阅读 [Seaborn中的distplot kdeplot rugplot jointplot](https://www.cnblogs.com/feffery/p/11128113.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris_data = pd.read_csv('data/iris.csv', index_col=\"Id\")\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''先画一个直方图(histogram)看一下花瓣长度分布'''\n",
    "sns.set(font_scale=1.0)\n",
    "sns.distplot(a=iris_data['Petal Length (cm)'], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码中的`kde=`参数用于控制是否输出核密度估计曲线。核密度估计(kernel density estimation)是在概率论中用来估计未知的密度函数，属于非参数检验方法之一。通过KDE图可以比较直观的看出数据样本本身的分布特征。\n",
    "\n",
    "也可以直接用`sns.kdeplot()`来画KDE曲线，`shade=`参数用于控制是否对曲线下方的区域填色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=iris_data['Petal Length (cm)'], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''绘制二维KDE图，深色处数据更为集中'''\n",
    "sns.jointplot(data=iris_data, x=\"Petal Length (cm)\", y=\"Sepal Width (cm)\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来我们用不同颜色代表不同种的鸢尾花，画一些图来了解物种之间的差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''分别载入已经分割好的不同种鸢尾花数据'''\n",
    "iris_set_data = pd.read_csv('data/iris_setosa.csv', index_col=\"Id\")\n",
    "iris_ver_data = pd.read_csv('data/iris_versicolor.csv', index_col=\"Id\")\n",
    "iris_vir_data = pd.read_csv('data/iris_virginica.csv', index_col=\"Id\")\n",
    "\n",
    "iris_vir_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''与前文折线图类似，我们可以将不同物种的直方图叠加到同一张图内'''\n",
    "sns.set(font_scale=1.4) # 字体缩放比例\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.title(\"各物种鸢尾花的花瓣长度分布直方图\")\n",
    "plt.xlabel(\"花瓣长度（厘米）\")\n",
    "plt.ylabel(\"样本数\")\n",
    "\n",
    "sns.distplot(a=iris_set_data['Petal Length (cm)'], label=\"Iris Setosa\", kde=False)\n",
    "sns.distplot(a=iris_ver_data['Petal Length (cm)'], label=\"Iris Versicolor\", kde=False)\n",
    "sns.distplot(a=iris_vir_data['Petal Length (cm)'], label=\"Iris Virginica\", kde=False)\n",
    "\n",
    "plt.legend() # 增加图例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''同样，也可以画KDE曲线'''\n",
    "sns.set(font_scale=1.4) # 字体缩放比例\n",
    "sns.set_style('white',{'font.sans-serif':['simhei','Arial']})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.title(\"各物种鸢尾花的花瓣长度KDE分布图\")\n",
    "plt.xlabel(\"花瓣长度（厘米）\")\n",
    "\n",
    "sns.kdeplot(data=iris_set_data['Petal Length (cm)'], label=\"Iris Setosa\", shade=True)\n",
    "sns.kdeplot(data=iris_ver_data['Petal Length (cm)'], label=\"Iris Versicolor\", shade=True)\n",
    "sns.kdeplot(data=iris_vir_data['Petal Length (cm)'], label=\"Iris Virginica\", shade=True)\n",
    "\n",
    "plt.legend() # 增加图例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些思考：\n",
    "  - 从花瓣长度来看，iris-ver和iris-vir似乎更为接近，而iris-setosa则表现出截然不同的特征。\n",
    "  - 我们可以训练一个模型，根据花瓣长度将iris-setosa区分出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图表选择与样式设置\n",
    "- 选择合适的图来解释数据背后的故事并不总是那么容易，需要结合数据特征、分析角度、经验等各项要素综合考虑。但我们可以考虑从以下三个角度入手：\n",
    "\n",
    "  - <font color=blue>趋势</font>：趋势可以理解为数据变化的模式。\n",
    "    - `lineplot()`折线图最适合展示一段时间内的数据变化趋势。\n",
    "  - <font color=blue>关系</font>：可以用不同的图表类型来理解变量之间的关系。\n",
    "    - `barplot()`条形图适用于展示组间的数量对比。\n",
    "    - `heatmap()`热力图适用于以颜色的方式展示表格中的数据。\n",
    "    - `scatterplot()`散点图展示两个连续变量之间的关系。如果引入颜色，则也可以展示与第三个变量的关系。\n",
    "    - `regplot()`散点图 + 回归曲线，可以更容易地展示两个变量间的线性关系。\n",
    "    - `lmplot()`引入颜色区分的散点图 + 回归曲线，可以更容易地展示三个变量间的关系。\n",
    "    - `swarmplot()`分类散点图展示连续变量和分类变量之间的关系。\n",
    "  - <font color=blue>分布</font>：对数据分布的可视化可以展示数据的期望。\n",
    "    - `displot()`直方图显示单个数值变量的分布。\n",
    "    - `kdeplot()`KDE图显示单个数值变量的密度分布。\n",
    "    - `jointplot()`更方便的展示二维KDE图和每个变量的KDE图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seaborn提供了丰富的接口（[文档](http://seaborn.pydata.org/api.html#style-api)）对图表的\n",
    "<font color=blue>样式</font>\n",
    "进行定制，这里是[教程](http://seaborn.pydata.org/tutorial/aesthetics.html)。同时，也推荐时常查阅与图表\n",
    "<font color=blue>颜色</font>\n",
    "相关的[教程](http://seaborn.pydata.org/tutorial/color_palettes.html)和[文档](http://seaborn.pydata.org/api.html#palette-api)。\n",
    "\n",
    "我们在前几小节的绘图中已经接触了一些图表样式的设置命令，如图表大小、字体缩放、图表主题样式等。这里只简单展示如何更改图表主题样式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们以4.1小节中的折线图为例'''\n",
    "spotify_data = pd.read_csv('data/spotify.csv', index_col=\"Date\", parse_dates=True)\n",
    "'''设置风格'''\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=spotify_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图我们设置主题样式为`white`，此外，Seaborn支持的主题样式还有`darkgrid`，`whitegrid`，`dark`，`ticks`共5种。感兴趣的同学可以通过更改上面代码框中的参数自行体验。（不要忘记双引号）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据建模\n",
    "- scikit-learn [官网](https://scikit-learn.org/stable/) [文档](https://scikit-learn.org/stable/user_guide.html) （又称sklearn）是功能强大的**机器学习建模** 工具包，提供了非常完备的预测性数据分析功能。包括分类算法（支持向量机、随机森林等）、回归算法（回归树、最近邻等）、聚类算法（K-means等）、数据降维（PCA等）、模型优化验证评估（网格搜索、交叉验证等）和数据预处理（数据清洗、特征提取）等功能。\n",
    "\n",
    "\n",
    "**几个概念**\n",
    "\n",
    "- 从学习方式的角度可以将机器学习分为 **有监督学习(supervised learning)** 和 **无监督学习(unsupervised learning)** 。\n",
    "  - 有监督学习：从标签化的数据集中训练模型。比如分类和回归。\n",
    "  - 无监督学习：用类别未知（无标签）的数据训练模型。比如聚类。\n",
    "  \n",
    "  \n",
    "- **超参数** ：在开始学习过程之前设置值的参数，而不是通过训练得到的模型参数。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。\n",
    "\n",
    "\n",
    "- **训练集、验证集、测试集** ：在数据分析过程中，为了保证模型在实际系统中能够起到预期作用，一般需要将样本分成独立的三部分：训练集（train set）用于训练模型参数。验证集（validation set)同样在模型训练中使用，用于在训练过程中确定模型效果，以便模型向着最优化的方向训练。测试集（test set）不在模型训练中使用，用于在模型训练完成后检验模型的性能。机器学习中常用的划分比例是 [0.7, 0.1, 0.2] 或 [0.8, 0.05, 0.15] 。\n",
    "\n",
    "\n",
    "- **交叉验证（cross validation）** ：当数据总量较少的时候，仅使用上面的方法将数据划分为三部分，训练出的模型效果比较差。常用的方法是留少部分做测试集，然后对其余N个样本采用K折交叉验证法（K-fold Cross Validation），基本步骤如下：\n",
    "  - 将样本打乱，均匀分成K份。\n",
    "  - 轮流选择其中K－1份做训练集，剩余的一份做验证集。\n",
    "  - 计算预测误差平方和，把K次的预测误差平方和的均值作为选择最优模型结构的依据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以聚类算法为例：\n",
    "\n",
    "![5-1](img/5-1.png)\n",
    "\n",
    "上图是sklearn官方网站给出的各种聚类算法的效果示意。聚类算法从原理上有基于密度、网格、分裂、层次的方法，要根据不同的数据分布特性选择合适的聚类算法。下面我们用鸢尾花数据集（因为太经典了，sklearn也内置了）构建一个聚类模型。\n",
    "\n",
    "- 聚类是在没有给定划分类别的情况下，根据数据相似度进行样本分组的一种方法。不需要数据标注，是一种非监督的学习算法。\n",
    "\n",
    "- 在商业上，聚类可以帮助市场分析人员从消费者数据库中区分中不同的消费群体，并且概括出每一类消费者的消费模式或消费习惯。\n",
    "\n",
    "- 聚类也可以作为数据分析算法中其他分析算法的一个预处理步骤，如异常值识别、连续特征离散化。以目前最流行的计算机视觉目标检测算法YOLOv5为例，在数据准备阶段，可以用聚类算法大致计算出训练集里的目标框的先验位置，这样可以加快模型训练的速度、提高模型预测的准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''先加载库和数据集'''\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris['data'] # 数据\n",
    "iris_label = iris['target'] # 标签\n",
    "iris_name = iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查看数据、标签'''\n",
    "'''标签的0/1/2就代表了4.4节中的setosa, versicolor和virginica''' # 也可以查看 iris['target_names']\n",
    "'''iris_data中4列数据分别代表花萼长度、花萼宽度、花瓣长度、花瓣宽度''' # 也可以查看 iris['feature_names']\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练一个数据标准化的规则，并应用在iris_data数据集上'''\n",
    "scaler = MinMaxScaler().fit(iris_data)\n",
    "iris_data_scaled = scaler.transform(iris_data)\n",
    "iris_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''用K-Means算法构建聚类模型，设置超参数：聚为3类'''\n",
    "km = KMeans(n_clusters=3).fit(iris_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''聚类结果'''\n",
    "y = km.fit_predict(iris_data)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''聚类结果的可视化展示'''\n",
    "import matplotlib.pyplot as plt\n",
    "'''先通过sklearn自带的TSNE方法将输入数据从四维降到二维'''\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "tsne = TSNE(n_components=2).fit(iris_data)\n",
    "df=pd.DataFrame(tsne.embedding_)\n",
    "df['labels'] = km.labels_\n",
    "df['labels_true'] = iris_label\n",
    "df1 = df[df['labels']==0]\n",
    "df2 = df[df['labels']==1] \n",
    "df3 = df[df['labels']==2]\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(df1[0],df1[1],'bo',df2[0],df2[1],'r*',df3[0],df3[1],'gD')\n",
    "plt.title('Predicted Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我们再看看真实情况是怎样的'''\n",
    "df1 = df[df['labels_true']==2]\n",
    "df2 = df[df['labels_true']==0] \n",
    "df3 = df[df['labels_true']==1] \n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(df1[0],df1[1],'bo',df2[0],df2[1],'r*',df3[0],df3[1],'gD')\n",
    "plt.title('True Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **聚类模型评价指标**\n",
    "> 聚类评价的标准是组内的对象相互之间是相似的（相关的），而不同组中的对象是不同的（不相关的）。即组内的相似性越大，组间差别越大，聚类效果就越好。sklearn的metrics模块提供的聚类模型评价指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''下面用FMI评价法作为示例'''\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "for i in range(2,7):\n",
    "    kmeans = KMeans(n_clusters = i,random_state=666).fit(iris_data)\n",
    "    score = fowlkes_mallows_score(iris_label, kmeans.labels_)\n",
    "    print('iris数据聚%d类FMI评价分值为：%f' %(i,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于 **分类** 和 **回归** 模型，同学们可以用本文档提供的数据集自行探索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![thx](img/thx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
